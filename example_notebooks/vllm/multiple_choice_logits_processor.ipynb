{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ed6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aerdem/projects/logits-processor-zoo\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89279fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aerdem/projects/LLM/llmenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 07-23 11:04:22 config.py:1222] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 07-23 11:04:22 llm_engine.py:161] Initializing an LLM engine (v0.5.0.post1) with config: model='google/gemma-1.1-2b-it', speculative_config=None, tokenizer='google/gemma-1.1-2b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=google/gemma-1.1-2b-it)\n",
      "INFO 07-23 11:04:25 weight_utils.py:218] Using model weights format ['*.safetensors']\n",
      "INFO 07-23 11:04:27 model_runner.py:160] Loading model weights took 4.6720 GB\n",
      "INFO 07-23 11:04:28 gpu_executor.py:83] # GPU blocks: 52902, # CPU blocks: 14563\n"
     ]
    }
   ],
   "source": [
    "from example_notebooks.vllm.utils import vLLMRunner\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "\n",
    "\n",
    "example_prompts = [\n",
    "\"\"\"\n",
    "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
    "0. Camera\n",
    "1. Screen resolution\n",
    "2. Operating System\n",
    "3. Battery\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \n",
    "\"\"\"\n",
    "Which user review doesn't belong to a summer dress?\n",
    "a) Looks good\n",
    "b) Keeps warm\n",
    "c) Too long\n",
    "d) Liked the color\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "runner = vLLMRunner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859aef8d",
   "metadata": {},
   "source": [
    "## Default Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf4c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "Answer:\n",
      "\n",
      "**\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "Answer:\n",
      "\n",
      "**\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.generate_response(example_prompts, max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc2f8a",
   "metadata": {},
   "source": [
    "## Multiple Choice Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d74eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "Answer:\n",
      "\n",
      "1\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "Answer:\n",
      "\n",
      "d\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"0\", \"1\", \"2\", \"3\"], delimiter=\".\")\n",
    "\n",
    "runner.generate_response(example_prompts[:1], [mclp], max_tokens=1)\n",
    "\n",
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"a\", \"b\", \"c\", \"d\"], delimiter=\")\")\n",
    "\n",
    "runner.generate_response(example_prompts[1:], [mclp], max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67163806",
   "metadata": {},
   "source": [
    "## Multiple Choice Answer by boosting first words of options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88032bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "Answer:\n",
      "\n",
      "3\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "Answer:\n",
      "\n",
      "c\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"0\", \"1\", \"2\", \"3\"], delimiter=\".\",\n",
    "                                     boost_first_words=1.0)\n",
    "\n",
    "runner.generate_response(example_prompts[:1], [mclp], max_tokens=1)\n",
    "\n",
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"a\", \"b\", \"c\", \"d\"], delimiter=\")\", \n",
    "                                     boost_first_words=1.0)\n",
    "\n",
    "runner.generate_response(example_prompts[1:], [mclp], max_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76937c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
