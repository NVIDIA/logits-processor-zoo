{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ed6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aerdem/projects/nvidia/logits-processor-zoo\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89279fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-19 10:37:26 config.py:1563] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 12-19 10:37:26 llm_engine.py:184] Initializing an LLM engine (v0.5.5) with config: model='google/gemma-1.1-2b-it', speculative_config=None, tokenizer='google/gemma-1.1-2b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=google/gemma-1.1-2b-it, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 12-19 10:37:27 model_runner.py:879] Starting to load model google/gemma-1.1-2b-it...\n",
      "INFO 12-19 10:37:28 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243efc7aaada47fd82cc1043c275f03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-19 10:37:30 model_runner.py:890] Loading model weights took 4.6720 GB\n",
      "INFO 12-19 10:37:32 gpu_executor.py:121] # GPU blocks: 49691, # CPU blocks: 14563\n"
     ]
    }
   ],
   "source": [
    "from example_notebooks.vllm.utils import vLLMRunner\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "\n",
    "\n",
    "example_prompts = [\n",
    "\"\"\"\n",
    "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
    "0. Camera\n",
    "1. Screen resolution\n",
    "2. Operating System\n",
    "3. Battery\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \n",
    "\"\"\"\n",
    "Which user review doesn't belong to a summer dress?\n",
    "a) Looks good\n",
    "b) Keeps warm\n",
    "c) Too long\n",
    "d) Liked the color\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "runner = vLLMRunner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859aef8d",
   "metadata": {},
   "source": [
    "## Default Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf4c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "Answer:\n",
      "\n",
      "**\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "Answer:\n",
      "\n",
      "**\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.generate_response(example_prompts, max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc2f8a",
   "metadata": {},
   "source": [
    "## Multiple Choice Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d74eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "Answer:\n",
      "\n",
      "1\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "Answer:\n",
      "\n",
      "d\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"0\", \"1\", \"2\", \"3\"], delimiter=\".\")\n",
    "\n",
    "runner.generate_response(example_prompts[:1], [mclp], max_tokens=1)\n",
    "\n",
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"a\", \"b\", \"c\", \"d\"], delimiter=\")\")\n",
    "\n",
    "runner.generate_response(example_prompts[1:], [mclp], max_tokens=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67163806",
   "metadata": {},
   "source": [
    "## Multiple Choice Answer by boosting first words of options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88032bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "I am getting a lot of calls during the day. What is more important for me to consider when I buy a new phone?\n",
      "0. Camera\n",
      "1. Screen resolution\n",
      "2. Operating System\n",
      "3. Battery\n",
      "\n",
      "Answer:\n",
      "\n",
      "3\n",
      "-----END-----\n",
      "\n",
      "Prompt: \n",
      "Which user review doesn't belong to a summer dress?\n",
      "a) Looks good\n",
      "b) Keeps warm\n",
      "c) Too long\n",
      "d) Liked the color\n",
      "\n",
      "Answer:\n",
      "\n",
      "c\n",
      "-----END-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"0\", \"1\", \"2\", \"3\"], delimiter=\".\",\n",
    "                                     boost_first_words=1.0)\n",
    "\n",
    "runner.generate_response(example_prompts[:1], [mclp], max_tokens=1)\n",
    "\n",
    "mclp = MultipleChoiceLogitsProcessor(runner.tokenizer, choices=[\"a\", \"b\", \"c\", \"d\"], delimiter=\")\", \n",
    "                                     boost_first_words=1.0)\n",
    "\n",
    "runner.generate_response(example_prompts[1:], [mclp], max_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76937c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
